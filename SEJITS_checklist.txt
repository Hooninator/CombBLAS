

splitting MPI/non-MPI
 - for pyCombBLAS, need to split definition of objects and operations into MPI using bits and non-MPI using bits.
   - problem with operations, because the serial parts are mixed with MPI parts. BinaryFunction does both, is it ok to just rip out a part of it?
      AL: I have this working on the test environment, there's still some bug with setup.py.

 - will have to do the same with CombBLAS in the future (embedded)

Embedding
(instead of having a pointer to callbacks, inline callbacks into serial part of kernel and compile that)
AL: What I think would be involved:
	in C++: Move the callback pointers up one level. It's crucial that the MPI parts do not need to be recompiled, so they will have to be compiled statically with pointers to the serial kernels. Since the MPI parts require known MPI_Datatype operands (so their size in bytes is known) I think we'd need to make 8 or 16 template instantiations of each kernel.
	in Python: I think that specialization would have to be moved into the kernel itself. When SpMV, for example, is called, we'd have to tell SEJITS the kernel to specialize, its datatypes, its callback code, and then pass it to a version of pyCombBLAS SpMV that accepts pluggable serial kernels (the one that has 8 or 16 instantiatons)

	I think this should only be done for SpMV and SpGEMM. The rest of the kernels (Reduce, Scale, etc) don't take as much time in the computation.

SEJITS Installation
 - copy headers to install directory (via setup.py)
 - Not clear where system paths will be, need to know what to pass into codepy.
 - why is pyCombBLAS passed into SEJITS? eg. pcb_function.py line 38



25% additon for Journal:
embedding (?)
profile the computation better, provide data on where time is spent in the computation
new graph algorithm (peer pressure clustering?)